{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Biodiversity and Conservation Status in National Parks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "This is my first python project shared on Github. I will explore and perform data analysis on 2 datasets, sourced from the National Parks Service.\n",
    "\n",
    "### Goals:\n",
    "I will be looking to answer more questions as I begin exploring the data, but these questions will guide my intial exploration:\n",
    "\n",
    "- What is the distribution of `conservation_status` for animals?  \n",
    "- Are certain types of species more likely to be endangered?  \n",
    "- Are the differences between species and their conservation status significant?  \n",
    "- Which species were spotted the most at each park?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**species_info.csv** - contains data about different species and their conservation status.  \n",
    "`category` - class of animal  \n",
    "`scientific_name` - the scientific name of each species  \n",
    "`common_name` - the common names of each species  \n",
    "`conservation_status` - each species' current conservation status  \n",
    "\n",
    "**observations.csv** - holds recorded sightings of different species at several national parks for the past 7 days.  \n",
    "`scientific_name` - the scientific name of each species  \n",
    "`park_name` - park where species were found  \n",
    "`observations` - the number of times each species was observed at the park"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV Files: inspect first 10 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During my review of the column names, I have decided not to name the DataFrame 'Observations' due to the identical column name. To avoid confusion, I will instead use 'tracking' as a synonym instead of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df = pd.read_csv(\"~/Desktop/GitHub/BioDiversity-Project/Analysis/species_info.csv\")\n",
    "tracking_df = pd.read_csv(\"~/Desktop/GitHub/BioDiversity-Project/Analysis/observations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging into the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only see `NaN` values in  **species_df** for the column `conservation_status`- this will be something to look into a bit deeper as I begin to clean the data.  \n",
    "*I also see that both df's contain the column `scientific_name`. This will be useful to act as a primary key, linking both tables by a shared relation if I choose to join both df's.*\n",
    "\n",
    "**For now, though, I want to continue exploring the data while looking more into each column to see if any others contain NaN, or other possible issues that could be addressed with data cleaning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df_shape = species_df.columns, species_df.shape\n",
    "\n",
    "species_df_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df_shape = tracking_df.columns, tracking_df.shape\n",
    "\n",
    "tracking_df_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_null = species_df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "species_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows, total_col = species_df.shape\n",
    "null_rows = species_null[0]\n",
    "null_per = (null_rows/total_rows) *100\n",
    "\n",
    "print(f\"{null_per.round(3)}% of the rows in the conservation_status column are null.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_null = tracking_df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "tracking_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diving deeper I see a majority of the rows in the `conservation_status` column have null values. I want to know if the missing values are: systematic, MAR, MCAR, or MNAR? Without much domain knowledge, I will look closer at the non-null values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_types = species_df['conservation_status'].unique()\n",
    "\n",
    "print(\"conservation_types:\", conservation_types)\n",
    "species_df['conservation_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Conservation Status`** is an ordinal categorical variable with 4 categories: \n",
    "- Species of Concern, \n",
    "- Endangered, \n",
    "- Threatened, \n",
    "- In recovery. \n",
    " \n",
    "**It seems less surprising now, why there is a significant portion of null values (96.72%) - it is common for a species to not fit 1 of the 4 categories, which suggests that `NaN` values represent *no* conservation status,i.e. the species is not at risk.**\n",
    "\n",
    "This insight allows me to make an important assumption: that `NaN` values are systematically missing due to the dataset only recording conservation status for species known to be at risk. However, it is crucial to remember that this is an assumption.\n",
    "\n",
    "To perform a more comprehensive analysis, I will modify the null values to represent a 'Healthy' conservation status, indicating that the species is not considered at risk. This relabeling allows me to include these records in my analysis without the need to delete the rows entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df['conservation_status'] = species_df['conservation_status'].fillna('Healthy').astype('category')\n",
    "#con_status = species_df['conservation_status'].astype('category')\n",
    "con_status = species_df['conservation_status']\n",
    "labels = con_status.unique()\n",
    "con_status_counts = con_status.value_counts()\n",
    "\n",
    "con_status_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = (con_status_counts/total_rows)*100\n",
    "\n",
    "prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some insight into Q1. What is the distribution of `conservation_status` for animals?  \n",
    "\n",
    "Before fully diving into Q1, I do want to quickly investigate the question with the current understanding so far established through the analysis up to this point. **Since I am not familiar with this dataset/domain of knowledge, I find it helpful to take extra time learning about the basic features, and how they relate.**\n",
    "\n",
    "For example, it is more obvious looking at the proportions above to understand the distribution of species this dataset contains. It prepares me for further EDA, where I'd be interested in learning more about the distribution of `conservation_status` by national park - maybe some parks are home to more at-risk species than other parks!\n",
    "\n",
    "### A visual of the `conservation_status` proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_labels = [f'{label} - {prop:.1f}%' for label, prop in zip(labels, prop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(con_status_counts)\n",
    "plt.title('Proportion of Conservation Status')\n",
    "plt.legend(legend_labels,bbox_to_anchor=(1, 0.5), loc='center left')\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is hard to see any color except for **blue** and **orange**, indicating the other values are much less frequent.\n",
    "\n",
    "With this additional understanding, I can think of 2 more questions I am interested in analyzing during EDA -- what is the proportion of `convservation_status` by:\n",
    "- `national_park`?; to investigate if some parks are more difficult for a species to survive in.\n",
    "- `category`?; to investigate if some categories of species have more difficulty surviving than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before performing in-depth EDA, I want to backup and finish the data cleaning.. I need to identify all duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dups = species_df.duplicated()\n",
    "t_dups = tracking_df.duplicated()\n",
    "\n",
    "s_dups.sum(), t_dups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = tracking_df[tracking_df.duplicated(keep=False)]\n",
    "\n",
    "duplicates.sort_values(by=['scientific_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows above are all duplicates. There seems to be no reason for including both records so i will now drop all duplicates, and check to ensure there are no further duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df = tracking_df.drop_duplicates()\n",
    "\n",
    "tracking_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point all null values have been handled, and all duplicates removed. The data is much cleaner!\n",
    "\n",
    "Now, it would be beneficial to merge the two dataframes, enabling more comprehensive analysis, such as examining the relationship between `conservation_status` and `common_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(species_df, tracking_df, on='scientific_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = data[data['scientific_name'] == 'Bos bison']\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "check2 = data[(data.park_name == 'Bryce National Park') & (data.conservation_status == 'Endangered')]\n",
    "\n",
    "check2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now see how helpful it is to combine both dataframes into 1 dataframe. With this quick example, 'check'/'check2' show that: a) The American Bison is 'Healthy' in all parks, and b) \n",
    "\n",
    "Perhaps, some parks have higher concentrations of non-healthy species? And if so, do some category types (e.g. mammal, fish,etc.) have a high liklihood of becoming non-healthy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=check.park_name,height=check.observations,color=['red','blue','green','black'])\n",
    "plt.xticks(np.arange(4)-0.5,check.park_name,rotation=45)\n",
    "plt.title(\"Bos bison Frequency by National Park\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot clearly highlights the national park in which the American Bison is most commonly sighted. \n",
    "**This sample of data visually helps me understand the dataset better, so when it comes to conducting a comprehensive analysis, I am more prepared.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "Before performing **Exploratory Data Analysis**, I want to learn about the summary statistics. Now that my data is clean, and both csv files are merged into 1 Dataframe (joined by their shared column, `scientific_name`), I think it is a great time to see the summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_stats = data.describe(include='all')\n",
    "sum_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 7 different values for `category`, still I will look closer...\n",
    "category_totals = data.groupby('category')['observations'].sum().sort_values()\n",
    "\n",
    "category_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see the average park has 142 observations, but let's also look closer here...\n",
    "park_totals = data.groupby('park_name')['observations'].sum().sort_values()\n",
    "\n",
    "park_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Distribution by National Park for All Species\n",
    "At this point the data is clean, summary stats are known, and I have started learning more about the relationships within the dataset.\n",
    "\n",
    "To begin my EDA now, I want to compare the total distribution of species across all national parks. This can help tell me if some parks are home to more species in general, and also individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "x = np.arange(len(data))\n",
    "\n",
    "colors = cm.tab10(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = park_totals.index\n",
    "height = park_totals\n",
    "\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.bar(x,height,color=colors)\n",
    "ax.set_xticks(ticks=np.arange(4)-.45,labels=x)\n",
    "ax.set_xticklabels(x,rotation=40)\n",
    "plt.title(\"Total Observations by National Park\")\n",
    "plt.xlabel(\"National Park\")\n",
    "plt.ylabel(\"Number of Observations\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most frequent observations occur in Yellowstone National Park. \n",
    "Now lets compare the distribution of conservation status with the types of species, to help answer q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_category = pd.pivot_table(species_df[species_df['conservation_status'] != 'Healthy'],\n",
    "                                      values = 'common_names',\n",
    "                                      index = 'conservation_status',\n",
    "                                      columns = 'category',\n",
    "                                      aggfunc = pd.Series.count)\n",
    "\n",
    "conservation_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_category.plot(kind = 'barh',\n",
    "                          subplots=True,\n",
    "                          xlabel = \"Observation Count\",\n",
    "                          title = 'Conservation Status Comparison',\n",
    "                          ylabel = \" \",\n",
    "                          figsize=(5,10),\n",
    "                          legend=False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will now combine conservation_status to compare ALL non-healthy observations by species category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df['protected'] = species_df['conservation_status'] != 'Healthy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected = species_df.groupby(['protected','category'])['scientific_name'].count().reset_index().pivot_table(values='scientific_name',\n",
    "                                                                                                             index='protected',\n",
    "                                                                                                             columns='category',\n",
    "                                                                                                             aggfunc='sum')\n",
    "\n",
    "protected_f = protected.loc[False]\n",
    "protected_t = protected.loc[True]\n",
    "protected.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_t.plot(kind = 'bar',\n",
    "              subplots=False,\n",
    "                 color=colors,\n",
    "               figsize=(10,10),\n",
    "               title=\"All Protected Species: Total Count\")\n",
    "              \n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Because this compares absolute values, it will be helpful to also compute the `conservation_status` by percentage for all species.** To compute this, I will first add a column to the species_df called 'protected' which represents if a species has a non-healthy `conservation_status`; this allows me to group all of the healthy and non-healthy species, to compare proprotions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_T = protected.T\n",
    "protected_T['ratio'] = (protected_t / (protected_t + protected_f))*100\n",
    "\n",
    "\n",
    "protected_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Although Birds have the most absolute protection, they are not the most likely to be protected! \n",
    "### Infact, on a proportional basis, Mammals are the most frequently protected at 17%; while Birds are protected 15% of the time.\n",
    "\n",
    "#### Could this point to a human bias - choosing to protect fellow mammals more than anything else?! Further analysis would need to look at factors contributing to decisions for protecting a species to answer this puzzle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significant Differences across Species?\n",
    "\n",
    "Now I will investigate the statistical significance of the species `conservation_status`, to help determine if there is a significant association between the species group (mammals, birds, etc.) and their conservation status (protected or not protected).\n",
    "\n",
    "**To determine statistical significance, I will use the Chi-Square test.** First, I will comput the contingency table as observed, and then expected, using scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will find the p values for  a chi-squared test between mammals and vascular plants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency1 = [[38,176],[46,4424]]\n",
    "\n",
    "contingency1 = pd.DataFrame(contingency1,columns=['O_Protected','O_Not-Protected'],index=['Mammals','Vascular Plants'])\n",
    "\n",
    "contingency1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The table above shows the observed ratios, while the table below shows the expected ratios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, pval, dof, ex = chi2_contingency(contingency1)\n",
    "\n",
    "ex = pd.DataFrame(ex.round(),columns=['e_Protected','e_Not-Protected'],index=['Mammals','Vascular Plants'])\n",
    "\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pval is extremely low! This gives me reasons to reject the **null hypothesis** which states there is no statistical significance between `conservation_status` and `category` of species - implying that random chance determines the number of protected observations. \n",
    "\n",
    "**The Chi-squared test has helped me determine that atleast for Mammals and Vascular Plants, there is a statistical difference between the observed protection count and the expected; where more mammals were protected than expected!**  \n",
    "*Might this be confirming my intial theory, that humans protect mammals over all else?!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Species are Most Common?\n",
    "\n",
    "Last question I will seek to answer is the most common species observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammals = species_df[species_df.category == \"Mammal\"].common_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = mammals.apply(lambda x: x.lower())\\\n",
    "        .apply(lambda x: x.replace(\"(\",\" \"))\\\n",
    "        .apply(lambda x: x.replace(\")\",\" \"))\\\n",
    "        .apply(lambda x: x.replace(\",\",\" \"))\\\n",
    "        .apply(lambda x: x.replace(\"-\",\" \"))\\\n",
    "        .apply(lambda x: x.replace(\"'\",\"\"))\\\n",
    "        .str.split()\n",
    "\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp1.apply(lambda x: [*set(x)])\n",
    "                    \n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = temp2.explode()\n",
    "\n",
    "temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_count = pd.DataFrame(temp3.value_counts().reset_index())\n",
    "\n",
    "name_count.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bats are the most common type of species observed, followed by Shrew.\n",
    "Because there are so many bats, I would like to know the vairety: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_variety = pd.DataFrame(species_df.common_names.apply(lambda x: x if ' Bat' in x else \"No\"))\n",
    "\n",
    "bat_true = bat_variety[bat_variety.common_names != \"No\"]\n",
    "\n",
    "bat_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Check the count to ensure all Bat types where included: {bat_true.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This project was a great reminder to me, just how important planning is at the onset of analysis. Specifically, when the data is outside of domain knowledge, I believe it is valuable to spend time critically thinking from the perspective of the researcher/data collector - there is a reason someone spent time collecting this data, which means they have expectations or hope to use it in some meaningful way. At the onset of the project, I did not spend enough time doing this.\n",
    "\n",
    "Therefore, as I was half way through the project I found myself discovering new truths about the dataset I originally overlooked; for instace, I did not realize that the conservation_status was dependent on the species, and not the park_name; this makes sense, because if an animal is endangered it is endangered everywhere, and not just in 1 location typically. **But my initial assumption was perhaps an animal could be endangered in 1 park but not the other.** \n",
    "\n",
    "The errenous assumption proved to add confusion throughout my initial analysis, and it was not until I circled back to the inital dataset descriptions and research questions, that I realized my understanding was not fully accurate.\n",
    "\n",
    "In the end, this project - while challenging my abilities as a data analyst - make me excited! Excited to apply the lessons i gained, so that next project I can produce even more insightful and meaningful analysis. I will spend additional time in future projects planning, and really trying to tap into the mindset of the original researcher that spent time collecting the data to begin with. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
